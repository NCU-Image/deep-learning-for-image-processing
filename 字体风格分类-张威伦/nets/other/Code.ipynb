{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 训练集 测试集 验证集 在一起后  按比例随机切分\n",
    "# 数据集文件下 gabor代表gabor特征提取后的数据，gen是lbp，hog是hog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import json\n",
    "from sklearn import svm\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 风格\n",
    "Data_Style_liu = os.listdir(r'/Users/william/Documents/数据集/lishu_resize/邓石如')\n",
    "Data_Style_ou = os.listdir(r'/Users/william/Documents/数据集/lishu_resize/伊秉绶')\n",
    "Data_Style_yan = os.listdir(r'/Users/william/Documents/数据集/lishu_resize/金农')\n",
    "Data_Style_zhao = os.listdir(r'/Users/william/Documents/数据集/lishu_resize/郑簠')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def minBinary(pixel):\n",
    "    length = len(pixel)\n",
    "    if length == 0:\n",
    "        print(\"ok\")\n",
    "    zero = ''\n",
    "    for i in range(length)[::-1]:\n",
    "        if pixel[i] == '0':\n",
    "            pixel = pixel[:i]\n",
    "            zero += '0'\n",
    "        else:\n",
    "            return zero + pixel\n",
    "    if len(pixel) == 0:\n",
    "        return '00000000'\n",
    "def originLBP(img,minBinary_bool=False):\n",
    "    frame = np.zeros(img.shape,dtype=img.dtype)*255\n",
    "    #print(image)\n",
    "    img = np.array(img,dtype=np.int32)\n",
    "    h,w = img.shape\n",
    "    for i in range(1,h-1):\n",
    "        for j in range(1,w-1):\n",
    "            value = img[i-1][j-1] + img[i-1][j] + img[i-1][j+1]\n",
    "            value += img[i][j-1] + img[i][j] + img[i][j+1]\n",
    "            value += img[i+1][j-1] + img[i+1][j] + img[i+1][j+1]\n",
    "            value /= 9\n",
    "            v_1 = str(int(img[i-1][j-1]> value))\n",
    "            v_2 = str(int(img[i-1][j]> value))\n",
    "            v_3 = str(int(img[i-1][j+1]> value))\n",
    "            v_4 = str(int(img[i][j+1]> value))\n",
    "            v_5 = str(int(img[i+1][j+1]> value))\n",
    "            v_6 = str(int(img[i+1][j]> value))\n",
    "            v_7 = str(int(img[i+1][j-1]> value))\n",
    "            v_8 = str(int(img[i][j-1]> value))\n",
    "            binary_value = v_1 +  v_2 +  v_3 +  v_4 +  v_5 +  v_6 +  v_7 +  v_8\n",
    "\n",
    "            if minBinary_bool:\n",
    "                binary_value = minBinary(str(binary_value))\n",
    "            frame[i][j] = int(binary_value,2)  \n",
    "\n",
    "    return frame\n",
    "min_Bin = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in Data_Style_liu:\n",
    "    print(i)\n",
    "    if 'DS_Store' in i:\n",
    "        continue\n",
    "    image = cv2.imread(r'/Users/william/Documents/数据集/lishu_resize/邓石如/'+str(i),0)\n",
    "    img = originLBP(image,min_Bin)\n",
    "    cv2.imwrite('/Users/william/Documents/数据集/lishu_resize/gen/0/'+str(i),img)\n",
    "    \n",
    "for i in Data_Style_ou:\n",
    "    print(i)\n",
    "    if 'DS_Store' in i:\n",
    "        continue\n",
    "    image = cv2.imread(r'/Users/william/Documents/数据集/lishu_resize/伊秉绶/'+str(i),0)\n",
    "    img = originLBP(image,min_Bin)\n",
    "    cv2.imwrite('/Users/william/Documents/数据集/lishu_resize/gen/1/'+str(i),img)\n",
    "for i in Data_Style_yan:\n",
    "    print(i)\n",
    "    if 'DS_Store' in i:\n",
    "        continue\n",
    "    image = cv2.imread(r'/Users/william/Documents/数据集/lishu_resize/金农/'+str(i),0)\n",
    "    img = originLBP(image,min_Bin)\n",
    "    cv2.imwrite('/Users/william/Documents/数据集/lishu_resize/gen/2/'+str(i),img)\n",
    "for i in Data_Style_zhao:\n",
    "    print(i)\n",
    "    if 'DS_Store' in i:\n",
    "        continue\n",
    "    image = cv2.imread(r'/Users/william/Documents/数据集/lishu_resize/郑簠/'+str(i),0)\n",
    "    img = originLBP(image,min_Bin)\n",
    "    cv2.imwrite('/Users/william/Documents/数据集/lishu_resize/gen/3/'+str(i),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_liu = 0\n",
    "data_ou = 0\n",
    "data_yan = 0\n",
    "data_zhao = 0\n",
    "\n",
    "for path in Data_Style_liu:\n",
    "    print(path)\n",
    "    if 'DS_Store' in path:\n",
    "        continue\n",
    "    image = cv2.imread('/Users/william/Documents/数据集/lishu_resize/gen/0/' + path,0)\n",
    "    image = np.reshape(image,(-1))\n",
    "    image = np.append(image,0)\n",
    "    image = np.array([image])\n",
    "    #print(image.shape)\n",
    "    if type(data_liu) == int:\n",
    "        data_liu = image\n",
    "    else:\n",
    "        data_liu = np.concatenate((data_liu,image),axis=0)\n",
    "\n",
    "# ou        \n",
    "for path in Data_Style_ou:\n",
    "    print(path)\n",
    "    if 'DS_Store' in i:\n",
    "        continue\n",
    "    image = cv2.imread('/Users/william/Documents/数据集/lishu_resize/gen/1/' + path,0)\n",
    "    image = np.reshape(image,(-1))\n",
    "    image = np.append(image,1)\n",
    "    image = np.array([image])\n",
    "    if type(data_ou) == int:\n",
    "        data_ou = image\n",
    "    else:\n",
    "        data_ou = np.concatenate((data_ou,image),axis=0)\n",
    "        \n",
    "# yan \n",
    "for path in Data_Style_yan:\n",
    "    print(path)\n",
    "    if 'DS_Store' in i:\n",
    "        continue\n",
    "    image = cv2.imread('/Users/william/Documents/数据集/lishu_resize/gen/2/' + path,0)\n",
    "    image = np.reshape(image,(-1))\n",
    "    image = np.append(image,2)\n",
    "    image = np.array([image])\n",
    "    if type(data_yan) == int:\n",
    "        data_yan = image\n",
    "    else:\n",
    "        data_yan = np.concatenate((data_yan,image),axis=0)\n",
    "\n",
    "# zhao\n",
    "for path in Data_Style_zhao:\n",
    "    print(path)\n",
    "    if 'DS_Store' in i:\n",
    "        continue\n",
    "    image = cv2.imread('/Users/william/Documents/数据集/lishu_resize/gen/3/' + path,0)\n",
    "    image = np.reshape(image,(-1))\n",
    "    image = np.append(image,3)\n",
    "    image = np.array([image])\n",
    "    if type(data_zhao) == int:\n",
    "        data_zhao = image\n",
    "    else:\n",
    "        data_zhao = np.concatenate((data_zhao,image),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ret = pd.DataFrame(data_liu)\n",
    "ret.to_csv('/Users/william/Documents/数据集/lishu_resize/gen/0.csv')\n",
    "\n",
    "ret = pd.DataFrame(data_ou)\n",
    "ret.to_csv('/Users/william/Documents/数据集/lishu_resize/gen/1.csv')\n",
    "\n",
    "ret = pd.DataFrame(data_yan)\n",
    "ret.to_csv('/Users/william/Documents/数据集/lishu_resize/gen/2.csv')\n",
    "\n",
    "ret = pd.DataFrame(data_zhao)\n",
    "ret.to_csv('/Users/william/Documents/数据集/lishu_resize/gen/3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# style 0-liu 1-ou 2-yan 3-zhao\n",
    "or_data_0 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/gen/0.csv'),dtype= 'float32')\n",
    "or_data_1 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/gen/1.csv'),dtype= 'float32')\n",
    "or_data_2 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/gen/2.csv'),dtype= 'float32')\n",
    "or_data_3 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/gen/3.csv'),dtype= 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 十进制转换二进制\n",
    "def decToBin(num):\n",
    "    arry = []   #定义一个空数组，用于存放2整除后的商\n",
    "    while True:\n",
    "        arry.append(str(num % 2))  #用列表的append方法追加\n",
    "        num = num // 2   #用地板除求num的值\n",
    "        if num == 0:     #若地板除后的值为0，那么退出循环\n",
    "            break\n",
    "\n",
    "    return \"\".join(arry[::-1]) #列表切片倒叙排列后再用join拼接\n",
    "\n",
    "# 计算 旋转不变性的最小值\n",
    "def minBinary(pixel):\n",
    "    length = len(pixel)\n",
    "    if length == 0:\n",
    "        print(\"ok\")\n",
    "    zero = ''\n",
    "    for i in range(length)[::-1]:\n",
    "        if pixel[i] == '0':\n",
    "            pixel = pixel[:i]\n",
    "            zero += '0'\n",
    "        else:\n",
    "            return zero + pixel\n",
    "    if len(pixel) == 0:\n",
    "        return '00000000'\n",
    "lis = []\n",
    "for i in range(0,256):\n",
    "    minb = decToBin(i)\n",
    "    #转换成2进制\n",
    "    val = minBinary(minb)\n",
    "    v = int(val,2)\n",
    "    if v not in lis:\n",
    "        lis.append(v)\n",
    "        \n",
    "def getLBPH(img_lbp,numPatterns,grid_x,grid_y,normed):\n",
    "    img_lbp = np.reshape(img_lbp,(64,-1))\n",
    "    '''\n",
    "    计算LBP特征图像的直方图LBPH\n",
    "    '''\n",
    "    h,w=img_lbp.shape\n",
    "    width = int(w / grid_x)\n",
    "    height = int(h / grid_y)\n",
    "    # 定义LBPH的行和列，grid_x*grid_y表示将图像分割的块数，numPatterns表示LBP值的模式种类\n",
    "    result = np.zeros((grid_x * grid_y,numPatterns),dtype=float)\n",
    "    resultRowIndex = 0\n",
    "    # 对图像进行分割，分割成grid_x*grid_y块，grid_x，grid_y默认为8\n",
    "    for i in range(grid_x):\n",
    "        for j in range(grid_y):\n",
    "            # 图像分块\n",
    "            src_cell = img_lbp[i*height:(i+1)*height,j*width:(j+1)*width]\n",
    "            # 计算直方图\n",
    "            hist_cell = getLocalRegionLBPH(src_cell,0,(numPatterns-1),normed)\n",
    "            #将直方图放到result中\n",
    "            result[resultRowIndex]=hist_cell\n",
    "            resultRowIndex+=1\n",
    "    return np.reshape(result,(-1))\n",
    "\n",
    "def getLocalRegionLBPH(src,minValue,maxValue,normed):\n",
    "    '''\n",
    "    计算一个LBP特征图像块的直方图\n",
    "    '''\n",
    "    data = np.reshape(src,(-1))\n",
    "    # 计算得到直方图bin的数目，直方图数组的大小\n",
    "    bins = maxValue - minValue + 1;\n",
    "    # 定义直方图每一维的bin的变化范围\n",
    "    ranges = (float(minValue),float(maxValue + 1))\n",
    "    hist, bin_edges = np.histogram(src, bins=bins, range=ranges, normed=False)\n",
    "\n",
    "    if normed:\n",
    "        hist = hist/sum(hist)\n",
    "    return hist\n",
    "\n",
    "#uniform_pattern = uniform_pattern_LBP(gray,3,8)\n",
    "#lbph = getLBPH(uniform_pattern,59,8,8,True)\n",
    "\n",
    "def get_data(lis=64*256,normed=False):\n",
    "    #lis 256 64*256\n",
    "    data_0 = or_data_0\n",
    "    data_1 = or_data_1\n",
    "    data_2 = or_data_2\n",
    "    data_3 = or_data_3\n",
    "\n",
    "    np.random.shuffle(data_0)\n",
    "    np.random.shuffle(data_1)\n",
    "    np.random.shuffle(data_2)\n",
    "    np.random.shuffle(data_3)\n",
    "\n",
    "    data_0 = data_0[:1800]\n",
    "    data_1 = data_1[:1800]\n",
    "    data_2 = data_2[:1800]\n",
    "    data_3 = data_3[:1800]\n",
    "    \n",
    "    normed = normed\n",
    "    # 对风格求 LBPH，整幅图求 LBPH\n",
    "    # liu\n",
    "    liu_feature_256_1 = np.zeros((data_0.shape[0],lis))\n",
    "    for i in range(0,data_0.shape[0]):\n",
    "        if lis==256:\n",
    "            hist,bin_edges=np.histogram(data_0[i,1:data_0.shape[1]-1],bins=lis,range=(0,lis),normed=normed)\n",
    "        else:\n",
    "            hist = getLBPH(data_0[i,1:data_0.shape[1]-1],256,8,8,normed)\n",
    "        liu_feature_256_1[i]=hist\n",
    "    liu_feature_256_1=np.c_[liu_feature_256_1,np.zeros((data_0.shape[0]))] \n",
    "\n",
    "    # ou\n",
    "    ou_feature_256_1 = np.zeros((data_1.shape[0],lis))\n",
    "    for i in range(0,data_1.shape[0]):\n",
    "        if lis==256:\n",
    "            hist,bin_edges=np.histogram(data_1[i,1:data_1.shape[1]-1],bins=lis,range=(0,lis),normed=normed)\n",
    "        else:\n",
    "            hist = getLBPH(data_1[i,1:data_1.shape[1]-1],256,8,8,normed)\n",
    "        ou_feature_256_1[i]=hist\n",
    "    ou_feature_256_1=np.c_[ou_feature_256_1,np.ones((data_1.shape[0]))] \n",
    "\n",
    "    # yan \n",
    "    yan_feature_256_1 = np.zeros((data_2.shape[0],lis))\n",
    "    for i in range(0,data_2.shape[0]):\n",
    "        if lis==256:\n",
    "            hist,bin_edges=np.histogram(data_2[i,1:data_2.shape[1]-1],bins=lis,range=(0,lis),normed=normed)\n",
    "        else:\n",
    "            hist = getLBPH(data_2[i,1:data_2.shape[1]-1],256,8,8,normed)\n",
    "        yan_feature_256_1[i]=hist\n",
    "    yan_feature_256_1=np.c_[yan_feature_256_1,np.ones((data_2.shape[0]))*2] \n",
    "\n",
    "    # zhao\n",
    "    zhao_feature_256_1 = np.zeros((data_3.shape[0],lis))\n",
    "    for i in range(0,data_3.shape[0]):\n",
    "        if lis==256:\n",
    "            hist,bin_edges=np.histogram(data_3[i,1:data_3.shape[1]-1],bins=lis,range=(0,lis),normed=normed)\n",
    "        else:\n",
    "            hist = getLBPH(data_3[i,1:data_3.shape[1]-1],256,8,8,normed)\n",
    "        zhao_feature_256_1[i]=hist\n",
    "    zhao_feature_256_1=np.c_[zhao_feature_256_1,np.ones((data_3.shape[0]))*3] \n",
    "    \n",
    "    liu_train, liu_val, liu_test = liu_feature_256_1[:540], liu_feature_256_1[540:720], liu_feature_256_1[720:]\n",
    "    ou_train, ou_val, ou_test = ou_feature_256_1[:540], ou_feature_256_1[540:720], ou_feature_256_1[720:]\n",
    "    yan_train, yan_val, yan_test = yan_feature_256_1[:540], yan_feature_256_1[540:720], yan_feature_256_1[720:]\n",
    "    zhao_train, zhao_val, zhao_test = zhao_feature_256_1[:540], zhao_feature_256_1[540:720], zhao_feature_256_1[720:]\n",
    "\n",
    "    data_train = np.concatenate((liu_train,ou_train,yan_train,zhao_train),axis=0)\n",
    "    data_val = np.concatenate((liu_val,ou_val,yan_val,zhao_val),axis=0)\n",
    "    data_test = np.concatenate((liu_test,ou_test,yan_test,zhao_test),axis=0)\n",
    "\n",
    "    np.random.shuffle(data_train)\n",
    "    np.random.shuffle(data_val)\n",
    "    np.random.shuffle(data_test)\n",
    "\n",
    "    data_train_x,data_train_y = data_train[:,:-1],data_train[:,-1]\n",
    "    data_val_x,data_val_y = data_val[:,:-1],data_val[:,-1]\n",
    "    data_test_x,data_test_y = data_test[:,:-1],data_test[:,-1]\n",
    "    print(data_test_x.shape, data_test_y.shape)\n",
    "#     with open('.\\\\LBP_feature_data.json', 'a+') as f:\n",
    "#         json.dump(data_test_x.tolist(), f)\n",
    "#     with open('.\\\\LBP_feature_label.json', 'a+') as f:\n",
    "#         json.dump(data_test_y.tolist(), f)\n",
    "    return data_train_x,data_train_y,data_val_x,data_val_y,data_test_x,data_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#clf = svm.SVC(probability=True)\n",
    "def SVM_f(data_train_x=0,data_train_y=0,data_val_x=0,data_val_y=0,data_test_x=0,data_test_y=0,C=1.0):\n",
    "    \n",
    "    clf = svm.SVC(C=C,kernel='rbf',probability=True)\n",
    "    clf.fit(data_train_x,data_train_y)\n",
    "    pre_train = clf.predict(data_train_x)\n",
    "    pre_val = clf.predict(data_val_x)\n",
    "    print(\"trian:\",accuracy_score(data_train_y,pre_train))\n",
    "    print(\"val:\",accuracy_score(data_val_y,pre_val))\n",
    "    \n",
    "    pre_test = clf.predict(data_test_x)\n",
    "    print(\"test:\",accuracy_score(data_test_y,pre_test))\n",
    "def C_lbp(C=1.0,lis=64*256,normed=False):\n",
    "    data_train_x,data_train_y,data_val_x,data_val_y,data_test_x,data_test_y = get_data(lis=lis,normed=normed)\n",
    "    #print(data_train_x.shape)\n",
    "    retu = SVM_f(data_train_x,data_train_y,data_val_x,data_val_y,data_test_x,data_test_y,C=C)\n",
    "    return retu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "C_lbp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cvShow(img):\n",
    "    cv2.imshow('name',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "def gamma(img):\n",
    "    return np.power(img/255.0,1)\n",
    "def div(img,cell_x,cell_y,cell_w):\n",
    "    cell=np.zeros(shape=(cell_x,cell_y,cell_w,cell_w))\n",
    "    img_x = np.split(img,cell_x,0)\n",
    "    for ie in range(cell_x):\n",
    "        img_y = np.split(img_x[ie],cell_y,1)\n",
    "        for je in range(cell_y):\n",
    "            cell[ie][je]=img_y[je]\n",
    "    return cell\n",
    "def get_bins(grad_cell,ang_cell):\n",
    "    # 12*12*8*8→12*12*9\n",
    "    bins=np.zeros(shape=(grad_cell.shape[0],grad_cell.shape[1],9))\n",
    "    \n",
    "    #print(grad_cell.shape)\n",
    "    #for i in range(grad_cell.shape[0]):\n",
    "    #    for j in range(grad_cell.shape[1]):\n",
    "     #       print(grad_cell[i,j])\n",
    "    \n",
    "    for i in range(grad_cell.shape[0]):\n",
    "        for j in range(grad_cell.shape[1]):\n",
    "            binn=np.zeros(9)\n",
    "            #grad_list=np.int8(grad_cell[i,j].flatten()) 超出字节，int8会转成负的\n",
    "            grad_list=np.floor(grad_cell[i,j].flatten())\n",
    "            #print(grad_list)\n",
    "            ang_list=ang_cell[i,j].flatten()\n",
    "            ang_list=np.int8(ang_list/20.0)#取下整\n",
    "            ang_list[ang_list>=9]=0 \n",
    "            #print(\"强度\"+str(grad_list))\n",
    "            #print(\"角度\"+str(ang_list))\n",
    "            for m in range(len(ang_list)): \n",
    "                binn[ang_list[m]]+= int(grad_list[m])\n",
    "            bins[i,j]=binn\n",
    "    return bins \n",
    "                \n",
    "def hog(img,cell_x,cell_y,cell_w):\n",
    "    # 计算x方向梯度、y方向梯度\n",
    "    gx=cv2.Sobel(img,ddepth=cv2.CV_64F,dx=1,dy=0,ksize=3) \n",
    "    gy=cv2.Sobel(img,ddepth=cv2.CV_64F,dx=0,dy=1,ksize=3)\n",
    "    \n",
    "    # 强度（大小）、梯度方向\n",
    "    gradient_magnitude=np.sqrt(gx*gx+gy*gy)\n",
    "    gradient_angle=np.arctan2(gx,gy)\n",
    "\n",
    "    # （牛） 角度转换到0-180   注意π=3.14→180°  \n",
    "    gradient_angle[gradient_angle>0]*=180/3.14\n",
    "    gradient_angle[gradient_angle<0]=(gradient_angle[gradient_angle<0]+3.14)*180/3.14\n",
    "    #print(gradient_magnitude.shape)\n",
    "    #cvShow(gradient_angle)\n",
    "    # 切分成 cell\n",
    "    grad_cell=div(gradient_magnitude,cell_x,cell_y,cell_w ) \n",
    "    ang_cell=div(gradient_angle,cell_x,cell_y,cell_w )\n",
    "    #print(grad_cell.shape)\n",
    "    #for i in range(grad_cell.shape[0]):\n",
    "    #    for j in range(grad_cell.shape[1]):\n",
    "      #      print(grad_cell[i,j])\n",
    "    \n",
    "    # 计算每个cell的特征 cell_x*cell_y*9\n",
    "    bins = get_bins(grad_cell,ang_cell)\n",
    "   \n",
    "    feature = []\n",
    "    for i in range(cell_x-1):\n",
    "        for j in range(cell_y-1):\n",
    "            temp = []\n",
    "            temp.append(bins[i,j])\n",
    "            temp.append(bins[i,j+1])\n",
    "            temp.append(bins[i+1,j])\n",
    "            temp.append(bins[i+1,j+1])\n",
    "            #temp -= np.mean(temp) \n",
    "            #feature.append(temp.flatten())\n",
    "            sumva = sum(sum(temp))\n",
    "            if sumva>0:\n",
    "                temp= temp/sumva\n",
    "            feature.append(temp)\n",
    "            #print(temp)\n",
    "    return np.array(feature).flatten()\n",
    "def hog_main(image):\n",
    "    #image = cv2.imread(img_path,0)\n",
    "    #print(\"原图的shape:\"+str(image.shape))\n",
    "    cell_w = 8\n",
    "    cell_x=int(image.shape[0]/cell_w)\n",
    "    cell_y=int(image.shape[1]/cell_w)\n",
    "    #print(\"cell_x:\"+str(cell_x))\n",
    "    #print(\"cell_y:\"+str(cell_y))\n",
    "    gammaing = gamma(image)*255\n",
    "    img = hog(gammaing,cell_x,cell_y,cell_w)\n",
    "    #print(img.shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 字体风格\n",
    "#\n",
    "Data_Style_liu = os.listdir(r'/Users/william/Documents/数据集/lishu_resize/邓石如')\n",
    "Data_Style_ou = os.listdir(r'/Users/william/Documents/数据集/lishu_resize/伊秉绶')\n",
    "Data_Style_yan = os.listdir(r'/Users/william/Documents/数据集/lishu_resize/金农')\n",
    "Data_Style_zhao = os.listdir(r'/Users/william/Documents/数据集/lishu_resize/郑簠')\n",
    "data_ou = 0\n",
    "data_yan = 0\n",
    "data_liu = 0\n",
    "data_zhao = 0\n",
    "\n",
    "# liu\n",
    "for i in Data_Style_liu:\n",
    "    image = cv2.imread(r'/Users/william/Documents/数据集/lishu_resize/邓石如/'+str(i),0)\n",
    "    feature = hog_main(image)\n",
    "\n",
    "    feature = np.array([feature])\n",
    "    if type(data_ou) == int:\n",
    "        data_ou = feature\n",
    "    else:\n",
    "        data_ou = np.concatenate((data_ou,feature),axis=0)\n",
    "ret = pd.DataFrame(data_ou)\n",
    "ret.to_csv('/Users/william/Documents/数据集/lishu_resize/hog/0.csv')\n",
    "\n",
    "\n",
    "# ou\n",
    "for i in Data_Style_ou:\n",
    "    image = cv2.imread(r'/Users/william/Documents/数据集/lishu_resize/伊秉绶/'+str(i),0)\n",
    "    feature = hog_main(image)\n",
    "    #print(feature.shape)\n",
    "    feature = np.array([feature])\n",
    "    if type(data_yan) == int:\n",
    "        data_yan = feature\n",
    "    else:\n",
    "        data_yan = np.concatenate((data_yan,feature),axis=0)\n",
    "ret = pd.DataFrame(data_yan)\n",
    "ret.to_csv('/Users/william/Documents/数据集/lishu_resize/hog/1.csv')\n",
    "\n",
    "\n",
    "# yan\n",
    "for i in Data_Style_yan:\n",
    "    image = cv2.imread(r'/Users/william/Documents/数据集/lishu_resize/金农/'+str(i),0)\n",
    "    feature = hog_main(image)\n",
    "    #print(feature.shape)\n",
    "    feature = np.array([feature])\n",
    "    if type(data_liu) == int:\n",
    "        data_liu = feature\n",
    "    else:\n",
    "        data_liu = np.concatenate((data_liu,feature),axis=0)\n",
    "ret = pd.DataFrame(data_liu)\n",
    "ret.to_csv('/Users/william/Documents/数据集/lishu_resize/hog/2.csv')\n",
    "\n",
    "\n",
    "# zhao\n",
    "for i in Data_Style_zhao:\n",
    "    image = cv2.imread(r'/Users/william/Documents/数据集/lishu_resize/郑簠/'+str(i),0)\n",
    "    feature = hog_main(image)\n",
    "    #print(feature.shape)\n",
    "    feature = np.array([feature])\n",
    "    if type(data_zhao) == int:\n",
    "        data_zhao = feature\n",
    "    else:\n",
    "        data_zhao = np.concatenate((data_zhao,feature),axis=0)\n",
    "ret = pd.DataFrame(data_zhao)\n",
    "ret.to_csv('/Users/william/Documents/数据集/lishu_resize/hog/3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# style liu ou yan zhao\n",
    "or_data_0 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/hog/0.csv'),dtype= 'float32')\n",
    "or_data_1 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/hog/1.csv'),dtype= 'float32')\n",
    "or_data_2 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/hog/2.csv'),dtype= 'float32')\n",
    "or_data_3 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/hog/3.csv'),dtype= 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data_0 = or_data_0\n",
    "    data_1 = or_data_1\n",
    "    data_2 = or_data_2\n",
    "    data_3 = or_data_3\n",
    "\n",
    "    np.random.shuffle(data_0)\n",
    "    np.random.shuffle(data_1)\n",
    "    np.random.shuffle(data_2)\n",
    "    np.random.shuffle(data_3)\n",
    "\n",
    "    data_0 = np.c_[data_0[:900],np.zeros(900)]\n",
    "    data_1 = np.c_[data_1[:900],np.ones(900)]\n",
    "    data_2 = np.c_[data_2[:900],np.ones(900)*2]\n",
    "    data_3 = np.c_[data_3[:900],np.ones(900)*3]\n",
    "    #print(data_0.shape)\n",
    "    #print(data_1.shape)\n",
    "    #print(data_2.shape)\n",
    "    #print(data_3.shape)\n",
    "    \n",
    "    A_s = 540\n",
    "    B_s = 720\n",
    "    \n",
    "    liu_train,liu_val,liu_test = data_0[:A_s],data_0[A_s:B_s],data_0[B_s:]\n",
    "    ou_train,ou_val,ou_test = data_1[:A_s],data_1[A_s:B_s],data_1[B_s:]\n",
    "    yan_train,yan_val,yan_test = data_2[:A_s],data_2[A_s:B_s],data_2[B_s:]\n",
    "    zhao_train,zhao_val,zhao_test = data_3[:A_s],data_3[A_s:B_s],data_3[B_s:]\n",
    "\n",
    "    data_train = np.concatenate((liu_train,ou_train,yan_train,zhao_train),axis=0)\n",
    "    data_val = np.concatenate((liu_val,ou_val,yan_val,zhao_val),axis=0)\n",
    "    data_test = np.concatenate((liu_test,ou_test,yan_test,zhao_test),axis=0)\n",
    "\n",
    "    np.random.shuffle(data_train)\n",
    "    np.random.shuffle(data_val)\n",
    "    np.random.shuffle(data_test)\n",
    "    # 去掉索引数字\n",
    "    data_train = data_train[:,1:]\n",
    "    data_val = data_val[:,1:]\n",
    "    data_test = data_test[:,1:]\n",
    "    \n",
    "    #print(data_train.shape)\n",
    "    #print(data_val.shape)\n",
    "    #print(data_test.shape)\n",
    "    \n",
    "    data_train_x,data_train_y = data_train[:,:-1],data_train[:,-1]\n",
    "    data_val_x,data_val_y = data_val[:,:-1],data_val[:,-1]\n",
    "    data_test_x,data_test_y = data_test[:,:-1],data_test[:,-1]\n",
    "    #print(data_train_x.shape,data_train_y.shape)\n",
    "    #print(data_val_x.shape,data_val_y.shape)\n",
    "    print(data_test_x.shape,data_test_y.shape)\n",
    "#     with open('.\\\\HOG_feature_data.json', 'a+') as f:\n",
    "#         json.dump(data_test_x.tolist(), f)\n",
    "#     with open('.\\\\HOG_feature_label.json', 'a+') as f:\n",
    "#         json.dump(data_test_y.tolist(), f)\n",
    "    return data_train_x,data_train_y,data_val_x,data_val_y,data_test_x,data_test_y\n",
    "#get_data()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def SVM_f(data_train_x=0,data_train_y=0,data_val_x=0,data_val_y=0,data_test_x=0,data_test_y=0,C=1.0):\n",
    "          #,data_test_x=0,data_test_y=0):\n",
    "    clf = svm.SVC(C=C,kernel='linear',probability=True)\n",
    "    clf.fit(data_train_x,data_train_y)\n",
    "    pre_train = clf.predict(data_train_x)\n",
    "    pre_val = clf.predict(data_val_x)\n",
    "    print(\"trian:\",accuracy_score(data_train_y,pre_train))\n",
    "    print(\"val:\",accuracy_score(data_val_y,pre_val))\n",
    "    pre_test = clf.predict(data_test_x)\n",
    "    print(\"test:\",accuracy_score(data_test_y,pre_test))\n",
    "    return data_train_y,pre_train,data_val_y,pre_val,data_test_x,data_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def C_hog(C=1.0):\n",
    "    data_train_x,data_train_y,data_val_x,data_val_y,data_test_x,data_test_y = get_data()\n",
    "    #print(data_train_x.shape)\n",
    "    retu = SVM_f(data_train_x,data_train_y,data_val_x,data_val_y,data_test_x,data_test_y,C=C)\n",
    "    return retu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "C_hog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gabor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Data_Name = [r'/Users/william/Documents/数据集/lishu_resize/郑簠/',r'/Users/william/Documents/数据集/lishu_resize/金农/',r'/Users/william/Documents/数据集/lishu_resize/伊秉绶/',r'/Users/william/Documents/数据集/lishu_resize/邓石如/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Path_name = ''\n",
    "#Data_Name = os.listdir(Path_name)\n",
    "from skimage import filters\n",
    "simt = 0\n",
    "for nam in Data_Name:\n",
    "    count=0\n",
    "    \n",
    "    #path = str(Path_name)+'/'+str(nam)\n",
    "    path = str(nam)\n",
    "    #print(path)\n",
    "    Data_0 = os.listdir(path)\n",
    "    data = np.zeros((len(Data_0),6144))\n",
    "    for i in Data_0:\n",
    "        image = cv2.imread(path+'/'+str(i),0)\n",
    "        #ret,image = cv2.threshold(image,127,255,cv2.THRESH_BINARY)\n",
    "        \n",
    "        feature = []\n",
    "        \"\"\"---------\"\"\"\n",
    "        # （0，45，90，135）和6个尺度（7，9，11，13，15，17）\n",
    "        for i in [0,45,90,135]:\n",
    "            for j in [7,9,11,13,15,17]:\n",
    "                #retval = cv2.getGaborKernel(ksize=(j,j),theta=i,sigma=10,lambd=10,gamma=1.2)\n",
    "                #retval = cv2.filter2D(image,-1,retval)\n",
    "                real, imag = filters.gabor(image, frequency=0.6,theta=i,n_stds=j)\n",
    "                #取模\n",
    "                retval=np.sqrt(real.astype(float)**2+imag.astype(float)**2)\n",
    "                #print(retval.shape)\n",
    "                retval = cv2.resize(retval,(0,0),fx=1/4,fy=1/4,interpolation=cv2.INTER_AREA)\n",
    "                retval = np.reshape(retval,-1)\n",
    "                #print(len(retval))\n",
    "                tmean = np.mean(retval)#求均值\n",
    "                tstd = np.std(retval)#求方差\n",
    "                newfea = (retval - tmean)/tstd#数值归一化\n",
    "                newfea= np.around(newfea, 4)\n",
    "                newfea = newfea.tolist()\n",
    "                #print(newfea)\n",
    "                feature = feature + newfea   \n",
    "        feature = np.array(feature)\n",
    "        #break\n",
    "        data[count] = np.array(feature)\n",
    "\n",
    "        count+=1 \n",
    "        # break\n",
    "    ret = pd.DataFrame(data)\n",
    "    ret.to_csv('/Users/william/Documents/数据集/lishu_resize/gabor/'+str(simt)+'.csv')\n",
    "    simt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 测试数据\n",
    "or_data_0 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/gabor/0.csv'),dtype= 'float32')\n",
    "or_data_1 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/gabor/1.csv'),dtype= 'float32')\n",
    "or_data_2 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/gabor/2.csv'),dtype= 'float32')\n",
    "or_data_3 = np.array(pd.read_csv('/Users/william/Documents/数据集/lishu_resize/gabor/3.csv'),dtype= 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data_0 = or_data_0\n",
    "    data_1 = or_data_1\n",
    "    data_2 = or_data_2\n",
    "    data_3 = or_data_3\n",
    "\n",
    "    np.random.shuffle(data_0)\n",
    "    np.random.shuffle(data_1)\n",
    "    np.random.shuffle(data_2)\n",
    "    np.random.shuffle(data_3)\n",
    "\n",
    "    data_0 = np.c_[data_0[:],np.ones(data_0.shape[0])*0]\n",
    "    data_1 = np.c_[data_1[:],np.ones(data_1.shape[0])*1]\n",
    "    data_2 = np.c_[data_2[:],np.ones(data_2.shape[0])*2]\n",
    "    data_3 = np.c_[data_3[:],np.ones(data_3.shape[0])*3]\n",
    "\n",
    "    A_1 = 540\n",
    "    A_2 = 720\n",
    "\n",
    "    #return \n",
    "    A_train,A_val,A_test = data_0[:A_1],data_0[A_1:A_2],data_0[A_2:]\n",
    "    B_train,B_val,B_test = data_1[:A_1],data_1[A_1:A_2],data_1[A_2:]\n",
    "    C_train,C_val,C_test = data_2[:A_1],data_2[A_1:A_2],data_2[A_2:]\n",
    "    D_train,D_val,D_test = data_3[:A_1],data_3[A_1:A_2],data_3[A_2:]\n",
    "    \n",
    "    data_train = np.concatenate((A_train,B_train,C_train,D_train),axis=0)\n",
    "    data_val = np.concatenate((A_val,B_val,C_val,D_val),axis=0)\n",
    "    data_test = np.concatenate((A_test,B_test,C_test,D_test),axis=0)\n",
    "    \n",
    "    np.random.shuffle(data_train)\n",
    "    np.random.shuffle(data_val)\n",
    "    np.random.shuffle(data_test)\n",
    "    # 去掉索引数字\n",
    "    data_train = data_train[:,1:]\n",
    "    data_val = data_val[:,1:]\n",
    "    data_test = data_test[:,1:]\n",
    "    #print(data_train.shape)\n",
    "    \n",
    "    data_train_x,data_train_y = data_train[:,:-1],data_train[:,-1]\n",
    "    data_val_x,data_val_y = data_val[:,:-1],data_val[:,-1]\n",
    "    data_test_x,data_test_y = data_test[:,:-1],data_test[:,-1]\n",
    "    print(data_test_x.shape, data_test_y.shape)\n",
    "#     with open('.\\\\GABOR_feature_data.json', 'a+') as f:\n",
    "#         json.dump(data_test_x.tolist(), f)\n",
    "#     with open('.\\\\GABOR_feature_label.json', 'a+') as f:\n",
    "#         json.dump(data_test_y.tolist(), f)\n",
    "    return data_train_x,data_train_y,data_val_x,data_val_y,data_test_x,data_test_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def SVM_f(data_train_x=0,data_train_y=0,data_val_x=0,data_val_y=0,data_test_x=0,data_test_y=0,C=1.0):\n",
    "          #,data_test_x=0,data_test_y=0):\n",
    "    clf = svm.SVC(C=C,kernel='rbf',probability=True)\n",
    "    clf.fit(data_train_x,data_train_y)\n",
    "    pre_train = clf.predict(data_train_x)\n",
    "    pre_val = clf.predict(data_val_x)\n",
    "    \n",
    "    train_value = accuracy_score(data_train_y,pre_train)\n",
    "    print(\"train:\",train_value)\n",
    "    \n",
    "    val_value = accuracy_score(data_val_y,pre_val)\n",
    "    print(\"val:\",val_value)\n",
    "    \n",
    "    pre_test = clf.predict(data_test_x)\n",
    "    \n",
    "    test_value = accuracy_score(data_test_y,pre_test)\n",
    "    print(\"test:\",test_value)\n",
    "    \n",
    "    value = (train_value,val_value,test_value)\n",
    "    \n",
    "    return data_train_y,pre_train,data_val_y,pre_val,data_test_x,data_test_y,value\n",
    "def C_gabor(C=1.0):\n",
    "    data_train_x,data_train_y,data_val_x,data_val_y,data_test_x,data_test_y = get_data()\n",
    "    #print(data_train_x.shape)\n",
    "    retu = SVM_f(data_train_x,data_train_y,data_val_x,data_val_y,data_test_x,data_test_y,C=C)\n",
    "    return retu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "C_gabor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}